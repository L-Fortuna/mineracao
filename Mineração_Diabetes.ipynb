{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L-Fortuna/mineracao/blob/LFortuna/Minera%C3%A7%C3%A3o_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**TRABALHO PARA CONCLUSÃO DA DISCIPLINA DE MINERAÇÃO DE DADOS: EXTRAÇÃO DE DADOS COM OBJETIVO DE PREVER DIABETES EM MULHERES**\n",
        "---\n",
        "\n",
        "                                                      LARISSA GEMINIANO FORTUNA\n",
        "                                                      LEONARDO BEARARI SILVA\n",
        "                                                      PROF.DR. MURILO VARGES DA SILVA\n",
        "\n",
        "Base de dados: https://www.kaggle.com/code/rishpande/pima-indians-diabetes-beginner\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Data: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome\n",
        "\n",
        "Features: 9\n",
        "\n",
        "Instances: 768\n",
        "\n",
        "Missing Values: 45\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##**1 - PRÉ-PROCESSAMENTO:**\n",
        "---\n",
        "\n",
        "A princípio, foi escolhida a base de dados relacionada anteriormente com objetivo de explorar a previsão de casos de diabetes em mulheres, tendo em vista fatores como idade, gravidez, histórico familiar, entre outros. Dessa forma, ficou definido que a principal investigação é a classificação de mulheres com diabetes.\n",
        "\n",
        "-\n",
        "\n",
        "Dos atributos presentes na base de dados, temos:\n",
        "\n",
        "**Pregnancies** (Número de gravidezes de cada mulher); **Glucose** (Teste de glicose); **Blood Pressure** (Nível de pressão ); **SkinThickness** (Espessura da pele); **Insulin** (Nível de insulina baseado em testes); **BMI** (Íncice de Massa Corpórea); **DiabetesPedigreeFunction** (Histórico familiar - pessoas da famíia com diabetes); **Age** (Idade); **Outcome** (Resultado: 0 para não diabtes / 1 para diabetes).\n",
        "\n"
      ],
      "metadata": {
        "id": "_YWesYLHsXHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALAÇÕES:\n",
        "\n",
        "pip install ucimlrepo\n",
        "pip install pandas\n",
        "pip install imbalanced-learn\n",
        "pip install matplotlib\n",
        "pip install seaborn\n",
        "pip install pandas-profiling\n"
      ],
      "metadata": {
        "id": "p2EbeWjiE_Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO DO PRÉ-PROCESSAMENTO:"
      ],
      "metadata": {
        "id": "xOfumeaLhR8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o conjunto de dados\n",
        "caminho_arquivo = r\"C:\\bdmineracao\\diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
        "dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "# Exibir os nomes das colunas\n",
        "print(\"Nomes das colunas:\")\n",
        "print(dados.columns)\n",
        "\n",
        "# Identificação e remoção de outliers\n",
        "def remove_outliers(df):\n",
        "    # Calcular a mediana para \"MentHlth\" e \"PhysHlth\"\n",
        "    mediana_mental = df['MentHlth'].median()\n",
        "    mediana_fisica = df['PhysHlth'].median()\n",
        "\n",
        "    # Identificar os outliers com base na mediana\n",
        "    outliers = ((df['MentHlth'] < 0) | (df['MentHlth'] > mediana_mental * 3) | (df['PhysHlth'] < 0) | (df['PhysHlth'] > mediana_fisica * 3))\n",
        "\n",
        "    # Remover as linhas que contêm outliers\n",
        "    df_filtrado = df[~outliers]\n",
        "\n",
        "    return df_filtrado\n",
        "\n",
        "# Remover outliers somente em \"MentHlth\" e \"PhysHlth\"\n",
        "dados_sem_outliers = remove_outliers(dados)\n",
        "\n",
        "# Exibir as primeiras 15 linhas do conjunto de dados sem outliers\n",
        "print(\"\\nPrimeiras 15 linhas do conjunto de dados sem outliers:\")\n",
        "print(dados_sem_outliers.head(25))\n"
      ],
      "metadata": {
        "id": "C4PItSpihYD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO DE PADRONIZAÇÃO:"
      ],
      "metadata": {
        "id": "-zOwi15Pf1A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Carregar o conjunto de dados\n",
        "caminho_arquivo = r\"C:\\bdmineracao\\diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
        "dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "# Identificação e remoção de outliers\n",
        "def remove_outliers(df):\n",
        "    # Calcular a mediana para \"MentHlth\" e \"PhysHlth\"\n",
        "    mediana_mental = df['MentHlth'].median()\n",
        "    mediana_fisica = df['PhysHlth'].median()\n",
        "\n",
        "    # Identificar os outliers com base na mediana\n",
        "    outliers = ((df['MentHlth'] < 0) | (df['MentHlth'] > mediana_mental * 3) | (df['PhysHlth'] < 0) | (df['PhysHlth'] > mediana_fisica * 3))\n",
        "\n",
        "    # Remover as linhas que contêm outliers\n",
        "    df_filtrado = df[~outliers].copy()  # Cria uma cópia do DataFrame para evitar o aviso\n",
        "\n",
        "    return df_filtrado\n",
        "\n",
        "# Função para normalizar os dados por escala mínima e máxima\n",
        "def normalize_min_max(df):\n",
        "    # Selecionar apenas as colunas numéricas para normalização\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "    # Criar um objeto MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Normalizar os dados apenas nas colunas numéricas\n",
        "    df.loc[:, numeric_cols] = scaler.fit_transform(df.loc[:, numeric_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Remover outliers somente em \"MentHlth\" e \"PhysHlth\"\n",
        "dados_sem_outliers = remove_outliers(dados)\n",
        "\n",
        "# Exibir as primeiras 15 linhas do conjunto de dados sem outliers\n",
        "print(\"\\nPrimeiras 15 linhas do conjunto de dados sem outliers:\")\n",
        "print(dados_sem_outliers.head(15))\n",
        "\n",
        "# Aplicar a normalização por escala mínima e máxima nos dados sem outliers\n",
        "dados_normalizados = normalize_min_max(dados_sem_outliers)\n",
        "\n",
        "# Exibir as primeiras 15 linhas dos dados normalizados\n",
        "print(\"\\nPrimeiras 15 linhas dos dados normalizados:\")\n",
        "print(dados_normalizados.head(15))\n"
      ],
      "metadata": {
        "id": "4KgS0kP1hLJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO DA NORMALIZAÇÃO:"
      ],
      "metadata": {
        "id": "mnkx0Q65gkhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "\n",
        "# Ignorar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def principal():\n",
        "    # Atualize os caminhos dos arquivos de entrada e saída\n",
        "    input_file = r'C:\\diabetes\\diabetes.csv'\n",
        "    output_file_abstencao = r'C:\\diabetes\\diabetesClear.csv'\n",
        "    output_file_normalizado = r'C:\\diabetes\\diabetesNormalizado.csv'  # Novo arquivo para dados normalizados\n",
        "\n",
        "    # Defina os nomes das colunas e características\n",
        "    names = ['Número Gestações', 'Glucose', 'pressao Arterial', 'Expessura da Pele', 'Insulina', 'IMC',\n",
        "             'Historico Familiar', 'Idade', 'Resultado']\n",
        "\n",
        "    # Leitura do arquivo CSV, pulando a primeira linha de cada coluna\n",
        "    df = pd.read_csv(input_file, names=names, skiprows=1, na_values='?')\n",
        "\n",
        "\n",
        "    # Cópia do DataFrame original\n",
        "    df_original = df.copy()\n",
        "\n",
        "    # Convertendo colunas para tipos numéricos\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Exibição das primeiras 15 linhas do arquivo\n",
        "    print(\"PRIMEIRAS 15 LINHAS\\n\")\n",
        "    print(df.head(15))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Exibição de informações gerais sobre os dados\n",
        "    print(\"INFORMAÇÕES GERAIS DOS DADOS\\n\")\n",
        "    print(df.info())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Descrição dos dados\n",
        "    print(\"DESCRIÇÃO DOS DADOS\\n\")\n",
        "    print(df.describe())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Identificação de colunas com valores faltantes\n",
        "    columns_missing_value = df.columns[df.isnull().any()]\n",
        "    print(\"COLUNAS COM VALORES FALTANTES\\n\")\n",
        "    print(columns_missing_value)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Escolha um método para lidar com valores ausentes (por exemplo, 'mode' para preenchimento com moda)\n",
        "    method = 'median'\n",
        "\n",
        "    for c in columns_missing_value:\n",
        "        UpdateMissingValues(df, c, method)\n",
        "\n",
        "    # Normalização Min-Max\n",
        "    features_to_normalize = ['Número Gestações', 'Glucose', 'pressao Arterial', 'Expessura da Pele', 'Insulina', 'IMC',\n",
        "                             'Idade']\n",
        "    df_normalized = normalize_data(df, features_to_normalize)\n",
        "\n",
        "    # Salvamento do DataFrame pré-processado em um novo arquivo CSV\n",
        "    df.to_csv(output_file_abstencao, index=False)\n",
        "\n",
        "    # Salvamento do DataFrame normalizado em um novo arquivo CSV\n",
        "    df_normalized.to_csv(output_file_normalizado, index=False)\n",
        "\n",
        "\n",
        "def UpdateMissingValues(df, column, method=\"median\", number=0):\n",
        "    if method == 'number':\n",
        "        # Substituindo valores ausentes por um número\n",
        "        df[column].fillna(number, inplace=True)\n",
        "    elif method == 'median':\n",
        "        # Substituindo valores ausentes pela mediana\n",
        "        median = df[column].median()\n",
        "        df[column].fillna(median, inplace=True)\n",
        "    elif method == 'mean':\n",
        "        # Substituindo valores ausentes pela média\n",
        "        mean = df[column].mean()\n",
        "        df[column].fillna(mean, inplace=True)\n",
        "    elif method == 'mode':\n",
        "        # Substituindo valores ausentes pela moda\n",
        "        mode = df[column].mode()[0]\n",
        "        df[column].fillna(mode, inplace=True)\n",
        "\n",
        "\n",
        "def normalize_data(df, features):\n",
        "    scaler = MinMaxScaler()\n",
        "    df_normalized = df.copy()\n",
        "    df_normalized[features] = scaler.fit_transform(df_normalized[features])\n",
        "    return df_normalized\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    principal()\n"
      ],
      "metadata": {
        "id": "NMkbrsGHhqPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO DO PCA:"
      ],
      "metadata": {
        "id": "ilz3EaWof9vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    # Caminho para o arquivo de entrada\n",
        "    input_file = r'C:\\diabetes\\diabetesNormalizado.csv'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Lendo o arquivo CSV para um DataFrame\n",
        "    df = pd.read_csv(input_file)\n",
        "    # Converter todas as colunas para numérico, forçando não numéricos a NaN\n",
        "    for column in df.columns[:-1]:  # Ignorando a última coluna 'Resultado'\n",
        "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "    # Exibindo informações sobre o DataFrame original\n",
        "    show_dataframe_info(df, \"DataFrame Original\")\n",
        "\n",
        "    # Selecionando características e alvo\n",
        "    features = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    target = 'Resultado'\n",
        "    x = df[features].values\n",
        "    y = df[target].values\n",
        "\n",
        "    # Manipulando valores ausentes\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    x_imputed = imputer.fit_transform(x)\n",
        "\n",
        "    # Padronizando as características\n",
        "    scaler = StandardScaler()\n",
        "    x_scaled = scaler.fit_transform(x_imputed)\n",
        "\n",
        "    # PCA 2D\n",
        "    visualize_pca_2d(x_scaled, y)\n",
        "\n",
        "\n",
        "# Função para exibir informações sobre um DataFrame\n",
        "def show_dataframe_info(df, message=\"\"):\n",
        "    print(message + \"\\n\")\n",
        "    print(df.info())  # Informações gerais sobre o DataFrame\n",
        "    print(df.describe())  # Estatísticas descritivas do DataFrame\n",
        "    print(df.head(10))  # Exibindo as primeiras linhas do DataFrame\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Exibição dos valores mínimo e máximo de cada característica\n",
        "    print(\"Valores Mínimos das Características:\")\n",
        "    print(df.min())\n",
        "    print(\"\\nValores Máximos das Características:\")\n",
        "    print(df.max())\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "# Função para visualizar o PCA em 2D\n",
        "def visualize_pca_2d(x, y):\n",
        "    # PCA 2D\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(x)\n",
        "\n",
        "    # Plotando os resultados do PCA 2D\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y, cmap=plt.cm.get_cmap('viridis', 2), alpha=0.5)\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.title('PCA 2D')\n",
        "    plt.colorbar(ticks=[0, 1], label='Resultado')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Chamada da função principal\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-0X7dow4hykp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO MATRIZ DE CORELAÇÃO MENOS PIOR:"
      ],
      "metadata": {
        "id": "FWWS3Bx9gCA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregar o conjunto de dados\n",
        "caminho_arquivo = r\"C:\\bdmineracao\\diabetes_012_health_indicators_BRFSS2015.csv\"\n",
        "dados = pd.read_csv(caminho_arquivo)\n",
        "\n",
        "# Selecionar as variáveis relevantes para o PCA\n",
        "variaveis_selecionadas = [\n",
        "    'Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
        "    'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
        "    'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
        "    'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income'\n",
        "]\n",
        "\n",
        "dados_selecionados = dados[variaveis_selecionadas]\n",
        "\n",
        "# Remover linhas com valores ausentes\n",
        "dados_selecionados.dropna(inplace=True)\n",
        "\n",
        "# Calcular a matriz de correlação\n",
        "matriz_correlacao = dados_selecionados.corr()\n",
        "\n",
        "# Visualizar a matriz de correlação usando um mapa de calor\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(matriz_correlacao, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Matriz de Correlação')\n",
        "plt.show()\n",
        "\n",
        "# Aplicar PCA para redução de dimensionalidade\n",
        "pca = PCA(n_components=2)\n",
        "dados_reduzidos = pca.fit_transform(dados_selecionados.drop(columns=['Diabetes_012']))  # Excluindo a coluna alvo\n",
        "\n",
        "# Criar um DataFrame com os dados reduzidos\n",
        "df_reduzido = pd.DataFrame(data=dados_reduzidos, columns=['PC1', 'PC2'])\n",
        "\n",
        "# Concatenar as colunas 'Diabetes_binary' do DataFrame original com os dados reduzidos\n",
        "df_final = pd.concat([dados[['Diabetes_012']], df_reduzido], axis=1)\n",
        "\n",
        "# Exibir os dados finais com redução de dimensionalidade\n",
        "print(\"\\nDados finais com redução de dimensionalidade:\")\n",
        "print(df_final.head())\n",
        "\n",
        "# Plotar o gráfico de dispersão dos dados reduzidos\n",
        "plt.figure(figsize=(6, 10))\n",
        "plt.scatter(df_final['PC1'], df_final['PC2'], c=df_final['Diabetes_012'], cmap='coolwarm', alpha=0.7)\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.title('PCA - Diabetes_binary em relação aos Componentes Principais')\n",
        "plt.colorbar(label='Diabetes_binary')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "orCatkdUh2FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODIGO DA ANALISE DESCRITIVA:"
      ],
      "metadata": {
        "id": "xbL4WV0qh7WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar o DataFrame original\n",
        "df = pd.read_csv(r'C:\\diabetes\\diabetesNormalizado.csv')\n",
        "\n",
        "# Converter todas as colunas para numérico, forçando não numéricos a NaN\n",
        "for column in df.columns[:-1]:  # Ignorando a última coluna 'Resultado'\n",
        "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "\n",
        "# Definir as faixas etárias\n",
        "bins = [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-100']\n",
        "\n",
        "# Adicionar uma coluna 'Faixa Etária' ao DataFrame\n",
        "df['Faixa Etária'] = pd.cut(df['Idade'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Agrupar os dados por faixa etária e resultado, contando o número de pessoas em cada grupo\n",
        "result_count = df.groupby(['Faixa Etária', 'Resultado']).size().unstack()\n",
        "\n",
        "# Plotar um gráfico de barras mostrando o número de pessoas em cada faixa etária para cada resultado\n",
        "result_count.plot(kind='bar', stacked=True)\n",
        "plt.xlabel('Faixa Etária')\n",
        "plt.ylabel('Número de Pessoas')\n",
        "plt.title('Número de Pessoas por Faixa Etária e Resultado')\n",
        "plt.legend(title='Resultado')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g6Rs59XHiPfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}